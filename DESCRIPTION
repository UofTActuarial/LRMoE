Package: LRMoExp
Type: Package
Title: Logit-Weighted Reduced Mixture-of-Experts
Version: 0.1.0
Author: Spark Tseung [aut, cre],
  Tsz Chai Fung [aut],
  Andrei L. Badescu [aut],
  Sheldon X. Lin [aut],
  Siyi Wei [dev]
Maintainer: Spark Tseung <spark.tseung@mail.utoronto.ca>
Description: The Logit-Weighted Reduced Mixture-of-Experts (LRMoE) 
  proposed by Fung et al. (2019) is a flexible framework actuarial loss modelling.
  For more details, see Fung et al. (2019) "A class of mixture of experts models for general insurance: Theoretical developments"
  published in Insurance: Mathematics and Economics, and
  Fung et al. (2019) "A CLASS OF MIXTURE OF EXPERTS MODELS FOR GENERAL INSURANCE: APPLICATION TO CORRELATED CLAIM FREQUENCIES"
  in ASTIN Bulletin: The Journal of the IAA.
License: GPL-3 + file LICENSE
Encoding: UTF-8
LazyData: true
Depends: R (>= 4.1.0)
Imports:
    Rcpp,
    RcppEigen,
    RcppNumerical,
    testthat,
    checkmate,
    R6,
    stats,
    matrixStats,
    actuar,
    rmutil,
    expint
RoxygenNote: 7.1.2
Roxygen: list(markdown = TRUE)
LinkingTo: 
    Rcpp, RcppEigen, RcppNumerical
